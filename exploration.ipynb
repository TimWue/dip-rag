{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from langchain.retrievers import ParentDocumentRetriever\n",
    "from langchain.storage import InMemoryStore\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_core.documents import Document\n",
    "import nest_asyncio\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.messages import (\n",
    "    HumanMessage,\n",
    "    SystemMessage,\n",
    ")\n",
    "from langchain_huggingface import ChatHuggingFace, HuggingFaceEndpoint\n",
    "from langchain_ollama.llms import OllamaLLM\n",
    "from langchain_openai import ChatOpenAI\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import copy\n",
    "from pydantic import BaseModel\n",
    "\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DIP Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = \"https://search.dip.bundestag.de/api/v1\"\n",
    "api_key = \"I9FKdCn.hbfefNWCY336dL6x62vfwNKpoN2RZ1gp21\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all documents metadata\n",
    "metadata_endpoint = \"plenarprotokoll\"\n",
    "headers = { \"Authorization\": f\"ApiKey {api_key}\"}\n",
    "\n",
    "def get_all_document_metadatas():   \n",
    "    metadata_url = f\"{base_url}/{metadata_endpoint}\"\n",
    "    return requests.get(metadata_url, headers=headers).json()[\"documents\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Text of one document\n",
    "fulltext_endpoint = \"plenarprotokoll-text\"\n",
    "params = {\"format\": \"xml\"}\n",
    "\n",
    "def get_text(document_id: str) -> str:\n",
    "    fulltext_url = f\"{base_url}/{fulltext_endpoint}/{document_id}\"\n",
    "    response = requests.get(fulltext_url, headers=headers, params=params)\n",
    "    return response.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Redner(BaseModel):\n",
    "    last_name: str\n",
    "    first_name: str\n",
    "    party: str | None\n",
    "    rolle: str | None\n",
    "    \n",
    "class Beitrag(BaseModel):\n",
    "    datum: str\n",
    "    rede: str\n",
    "    redner: Redner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_beitrag_from_rede_tag(datum: str, rede_tag) -> Beitrag:\n",
    "    # Get redner\n",
    "    redner_tag = rede_tag.find('redner')\n",
    "    first_name = redner_tag.find('vorname').text\n",
    "    last_name = redner_tag.find('nachname').text\n",
    "    party = redner_tag.find('fraktion').text if redner_tag.find('fraktion') else \"\"\n",
    "    rolle = redner_tag.find('rolle_lang').text if redner_tag.find('rolle_lang') else \"\"\n",
    "    redner = Redner(last_name=last_name, first_name=first_name, party=party,rolle=rolle)\n",
    "    redner_tag.decompose()\n",
    "\n",
    "    # Delete comments\n",
    "    for kommentar in rede_tag.find_all('kommentar'):\n",
    "        kommentar.decompose()\n",
    "\n",
    "    return Beitrag(redner=redner, rede=rede_tag.text, datum=datum)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadatas = get_all_document_metadatas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n",
      "11.10.2024\n"
     ]
    }
   ],
   "source": [
    "index = 3\n",
    "xml_url = metadatas[index][\"fundstelle\"][\"xml_url\"]\n",
    "xml_content = requests.get(xml_url).content\n",
    "soup = BeautifulSoup(xml_content, features='xml')\n",
    "\n",
    "all_reden_tags = soup.find_all(\"rede\")\n",
    "beitraege = []\n",
    "\n",
    "datum = soup.find(\"datum\").get(\"date\")\n",
    "for rede_tag in all_reden_tags:\n",
    "    rede_tag_cp = copy.deepcopy(rede_tag)\n",
    "    beitrag = get_beitrag_from_rede_tag(datum=datum, rede_tag=rede_tag_cp)\n",
    "    beitraege.append(beitrag)\n",
    "print(len(beitraege))\n",
    "print(beitraege[0].datum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create ParentDocumentRetriever\n",
    "embedding_model = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "parent_splitter = RecursiveCharacterTextSplitter(chunk_size=2000)\n",
    "child_splitter = RecursiveCharacterTextSplitter(chunk_size=400)\n",
    "vectorstore = Chroma(\n",
    "    collection_name=\"split_parents\", embedding_function=HuggingFaceEmbeddings(model_name=embedding_model)\n",
    ")\n",
    "store = InMemoryStore()\n",
    "\n",
    "retriever = ParentDocumentRetriever(\n",
    "    vectorstore=vectorstore,\n",
    "    docstore=store,\n",
    "    child_splitter=child_splitter,\n",
    "    parent_splitter=parent_splitter,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_langchain_document_from_beitrag(beitrag: Beitrag) -> Document:\n",
    "    redner_dict = beitrag.redner.dict()\n",
    "    metadata = {}\n",
    "    metadata.update(redner_dict)\n",
    "    metadata.update({\"datum\": beitrag.datum})\n",
    "    return Document(page_content=beitrag.rede, metadata=metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [get_langchain_document_from_beitrag(beitrag) for beitrag in beitraege]\n",
    "retriever.add_documents(documents=documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to /home/tim/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "# Load Generation Model\n",
    "llama_model_3 = \"meta-llama/Llama-3.2-3B-Instruct\"\n",
    "mixtral_model = \"mistralai/Mixtral-8x7B-Instruct-v0.1\"\n",
    "llama_2b_70b = \"meta-llama/Llama-2-70b-chat-hf\"\n",
    "openai_gpt_3_5 = \"gpt-3.5-turbo\"\n",
    "\n",
    "llm = HuggingFaceEndpoint(\n",
    "    repo_id=mixtral_model,\n",
    "    task=\"text-generation\",\n",
    "    max_new_tokens=1024,\n",
    ")\n",
    "\n",
    "chat_model = ChatOpenAI(model=openai_gpt_3_5)\n",
    "#chat_model = ChatHuggingFace(llm=llm)\n",
    "fact_check_model = ChatHuggingFace(llm=llm)\n",
    "#chat_model = OllamaLLM(model=\"mistral\")\n",
    "#fact_check_model = OllamaLLM(model=\"llama3.2:1b\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_docs(documents: list[Document]) -> str:\n",
    "    return \"\\n\\n\".join(document.page_content for document in documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rag_answer(prompt: str):\n",
    "    documents = retriever.invoke(prompt,)\n",
    "    context = format_docs(documents=documents)\n",
    "\n",
    "    simple_rag_prompt = (\n",
    "        \"Beantworte die Frage mit Hilfe der folgenden Kontextinformationen. \"\n",
    "        \"Wenn du die Antwort nicht weißt, sag einfach, dass du die Antwort nicht kennst. \"\n",
    "        \"Verwende zu Beantwortung nur die Informationen im Kontext. Verwende kein externes Wissen. \"\n",
    "        \"Verwende maximal fünf Sätze und fasse die Antwort kurz zusammen.\"\n",
    "        f\"Frage: {prompt}\"\n",
    "        f\"Kontext: {context}\"\n",
    "        \"Antwort: \" \n",
    "        )\n",
    "\n",
    "    simple_system_prompt =  \"Du bist ein Assistent für die Beantwortung von Fragen bezüglich Plenarsitzungen des Deutschen Bundestags.\"\n",
    "\n",
    "    messages = [\n",
    "        SystemMessage(content=simple_system_prompt),\n",
    "        HumanMessage(\n",
    "            content=simple_rag_prompt\n",
    "        ),\n",
    "    ]\n",
    "\n",
    "    answer = chat_model.invoke(messages).content\n",
    "    return (answer, documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Self Fact-Checking\n",
    "def check_facts(answer:str, documents: list[Document])-> tuple[bool, str]:\n",
    "    context = format_docs(documents=documents)\n",
    "\n",
    "    fact_checking_prompt = (\n",
    "        \"Du hast die Aufgabe, herauszufinden, ob die Hypothese begründet ist und mit den Beweisen übereinstimmt. \"\n",
    "        \"Verwende nur den Inhalt der Beweise und stütze dich nicht auf externes Wissen. \"\n",
    "        f\"Antworte mit ja/nein. Beweise: {context} \"\n",
    "        f\"Hypothese: {answer}: \"\n",
    "        \"Antwort: \"\n",
    "    )\n",
    "\n",
    "    ai_msg = fact_check_model.invoke([\n",
    "        HumanMessage(\n",
    "            content=fact_checking_prompt\n",
    "        ),\n",
    "    ]).content\n",
    "    is_okay = ai_msg.lower().strip().startswith(\"ja\")\n",
    "    return (is_okay, ai_msg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n",
      "Fact-Check: OKAY\n",
      "Die SPD unterstützt das Gesetz zur Stärkung der Strukturen gegen sexuelle Gewalt an Kindern und Jugendlichen, betont jedoch die Notwendigkeit von Nachbesserungen, insbesondere hinsichtlich der Verfügbarkeit und Finanzierung von Beratungsstellen sowie der Klarheit in Begrifflichkeiten und Zuständigkeiten. Die Partei begrüßt die geplanten Maßnahmen zur Stärkung der Prävention durch Schulungen von Fachkräften in der Jugendhilfe, Kitas, Schulen, Jugendämtern und gesundheitlichen Einrichtungen. Zudem betont die SPD die Wichtigkeit der Einbindung und Stärkung der Rechte von Betroffenen durch den verankerten Betroffenenrat und die Aufarbeitungskommission.\n"
     ]
    }
   ],
   "source": [
    "# Ask RAG\n",
    "prompt = \"Was sagt die SPD zur Stärkung der Strukturen gegen sexuelle Gewalt gegen Kinder und Jugendliche??\"\n",
    "(answer, documents) = get_rag_answer(prompt=prompt)\n",
    "(is_based_on_facts, fact_checking_answer) = check_facts(answer=answer, documents=documents)\n",
    "\n",
    "print(f\"Fact-Check: {'OKAY' if is_based_on_facts else 'NOT OKAY'}\")\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Ja, die Hypothese wird bestätigt. Aus dem Stenografischen Bericht geht hervor, dass Stephan Brandner (AfD) Herrn Steffen als \"Hetzer\" bezeichnet hat.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fact_checking_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Evaluation Dataset\n",
    "\n",
    "evaluation_questions = [\n",
    "    \"Wer nannte Herrn Steffen einen Hetzer?\"\n",
    "]\n",
    "\n",
    "evaluation_answers = [\n",
    "    \"Stephan Brandner (AfD) nannte Herrn Steffen einen 'Hetzer'.\"\n",
    "]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
